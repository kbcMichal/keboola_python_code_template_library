{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34a3e15-226d-41d5-932a-b488b310b273",
   "metadata": {},
   "source": [
    "# Using MLFlow model in Keboola Transformation\n",
    "\n",
    "This notebook demonstrates how to use a model registered and deployed in Keboola using MLFlow. Ensure you have gone through the **Getting Started** - **Working_With_MLFlow_in_Keboola** notebook to register and deploy your model first.\n",
    "\n",
    "## Steps Included:\n",
    "1. Initialize MLFlow\n",
    "2. Load the dataset using the Keboola Common Interface\n",
    "3. Invoke the deployed model\n",
    "4. Log model monitoring metrics\n",
    "5. End the MLFlow run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b02d8-83ec-475c-9d76-9d9f21175dcc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Initialize MLFlow and Set Experiment\n",
    "\n",
    "You can log every usage of your deployed model into an MLFlow experiment as runs. This step is optional, but highly recommended for better tracking and monitoring. Please enter an experiment name or select one from the existing experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ea8bd-0c0d-4bd7-b8d4-8860e531fd1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import mlflow\n",
    "import datetime\n",
    "from keboola.component import CommonInterface\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialize Keboola Common Interface\n",
    "ci = CommonInterface()\n",
    "\n",
    "# Widgets for experiment name\n",
    "experiment_name_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter the experiment name',\n",
    "    description='Experiment Name:',\n",
    "    disabled=False\n",
    ")\n",
    "display(experiment_name_widget)\n",
    "\n",
    "# Widgets to confirm logging to MLFlow\n",
    "log_to_mlflow_widget = widgets.ToggleButtons(\n",
    "    options=['Yes', 'No'],\n",
    "    description='Log to MLFlow?',\n",
    "    disabled=False,\n",
    "    button_style=''\n",
    ")\n",
    "display(log_to_mlflow_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55bd17-9f80-4b7c-972b-d970282fdf24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize MLFlow and set experiment\n",
    "if log_to_mlflow_widget.value == 'Yes':\n",
    "    experiment_name = experiment_name_widget.value\n",
    "    if experiment_name:\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    else:\n",
    "        raise ValueError(\"The experiment name must be provided if logging to MLFlow is enabled.\")\n",
    "\n",
    "    # Start MLFlow run\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # Log initial parameters\n",
    "    mlflow.log_param('experiment_name', experiment_name)\n",
    "    mlflow.log_param('start_time', datetime.datetime.now().isoformat())\n",
    "    print(f\"MLFlow experiment '{experiment_name}' started.\")\n",
    "else:\n",
    "    print(\"Skipping MLFlow logging.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2afb5a-73f9-4341-aaf1-6e77bbdf565c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Load the Dataset\n",
    "\n",
    "We will use the Keboola Common Interface to load the input dataset. Ensure you have configured your input mapping in Keboola.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16ec8b-e067-4569-aee9-551707352e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load input tables\n",
    "input_tables = ci.get_input_tables_definitions()\n",
    "\n",
    "# Create a dropdown widget for selecting a table\n",
    "if input_tables:\n",
    "    table_list = [table.full_path for table in input_tables]\n",
    "    tables_dropdown = widgets.Dropdown(options=table_list, value=table_list[0], description='Table:', disabled=False)\n",
    "    display(tables_dropdown)\n",
    "else:\n",
    "    logging.warning(\"No tables found. Please ensure you have loaded tables into the workspace using the table input mapping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd4fd1-630d-413e-b07c-3c6781dd5618",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Specify the Model Endpoint URL\n",
    "\n",
    "Enter the endpoint URL of the deployed model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90221571-60b7-4811-8490-646068ee5441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Widget to enter the endpoint URL\n",
    "endpoint_url_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter the endpoint URL of the deployed model',\n",
    "    description='Endpoint URL:',\n",
    "    disabled=False\n",
    ")\n",
    "display(endpoint_url_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861e84e-049c-43b6-9f68-bdcaed882f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the selected dataset\n",
    "table_path = tables_dropdown.value\n",
    "dataframe = pd.read_csv(table_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "display(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be49ef-4a95-4969-97d7-be82a76f3a38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Invoke the Deployed Model\n",
    "\n",
    "We will send the processed dataframe to the model endpoint and receive predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185a3f4-272f-4110-853c-9bcd4b8e155e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the endpoint URL\n",
    "endpoint_url = endpoint_url_widget.value\n",
    "\n",
    "# Ensure the endpoint URL is provided\n",
    "if not endpoint_url:\n",
    "    raise ValueError(\"The endpoint URL must be provided.\")\n",
    "\n",
    "# Send request to the model endpoint and store the result\n",
    "response = requests.post(\n",
    "    url=endpoint_url,\n",
    "    headers={'Content-Type': 'application/json; format=pandas-split'},\n",
    "    data=dataframe.to_json(orient='split')\n",
    ")\n",
    "\n",
    "# Check for errors in the response\n",
    "if response.status_code != 200:\n",
    "    raise ValueError(f\"Error in model invocation: {response.text}\")\n",
    "\n",
    "# Add the predicted scores to the dataframe\n",
    "dataframe['score'] = response.json()\n",
    "\n",
    "# Save the results to the output path\n",
    "output_path = 'out/tables/nlp_stats_score.csv'\n",
    "dataframe.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3688a-cb67-4a53-b249-4b81dcdc3c8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Log Model Monitoring Metrics\n",
    "\n",
    "Log the descriptive statistics of the dataframe for model monitoring.\n",
    "**Applicable if you selected MLFlow logging and entered the experiment name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3368f-39f0-4236-b110-2d10e827682b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log model monitoring metrics\n",
    "if log_to_mlflow_widget.value == 'Yes':\n",
    "    dataframe_desc = dataframe.describe()\n",
    "    vals = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    for col in dataframe.columns:\n",
    "        if col != 'score':  # Do not log metrics for the score column\n",
    "            for val in vals:\n",
    "                mlflow.log_metric(f'{col}_{val.replace(\"%\", \"_pct\")}', dataframe_desc.loc[val, col])\n",
    "    print(\"Model monitoring metrics logged to MLFlow.\")\n",
    "else:\n",
    "    print(\"Skipping logging of model monitoring metrics.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42df233-78fc-4cfa-8b03-e9640a3f8f92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## End the MLFlow Run\n",
    "\n",
    "End the MLFlow run and log the execution time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6c4cc-067c-4466-af91-642e34803b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# End MLFlow run\n",
    "if log_to_mlflow_widget.value == 'Yes':\n",
    "    end_time = datetime.datetime.now()\n",
    "    time_delta = (end_time - mlflow.active_run().info.start_time).total_seconds()\n",
    "\n",
    "    mlflow.log_metric('execution_time', time_delta)\n",
    "    mlflow.end_run()\n",
    "\n",
    "    print(\"MLFlow run ended.\")\n",
    "else:\n",
    "    print(\"Skipping ending MLFlow run.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
